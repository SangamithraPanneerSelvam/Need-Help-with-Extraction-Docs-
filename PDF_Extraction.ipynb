{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tika in e:\\anaconda\\lib\\site-packages (1.24)\n",
      "Requirement already satisfied: requests in e:\\anaconda\\lib\\site-packages (from tika) (2.24.0)\n",
      "Requirement already satisfied: setuptools in e:\\anaconda\\lib\\site-packages (from tika) (50.3.1.post20201107)\n",
      "Requirement already satisfied: idna<3,>=2.5 in e:\\anaconda\\lib\\site-packages (from requests->tika) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\lib\\site-packages (from requests->tika) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in e:\\anaconda\\lib\\site-packages (from requests->tika) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in e:\\anaconda\\lib\\site-packages (from requests->tika) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in e:\\anaconda\\lib\\site-packages (1.26.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfminer.six in e:\\anaconda\\lib\\site-packages (20201018)\n",
      "Requirement already satisfied: chardet; python_version > \"3.0\" in e:\\anaconda\\lib\\site-packages (from pdfminer.six) (3.0.4)\n",
      "Requirement already satisfied: cryptography in e:\\anaconda\\lib\\site-packages (from pdfminer.six) (3.1.1)\n",
      "Requirement already satisfied: sortedcontainers in e:\\anaconda\\lib\\site-packages (from pdfminer.six) (2.2.2)\n",
      "Requirement already satisfied: six>=1.4.1 in e:\\anaconda\\lib\\site-packages (from cryptography->pdfminer.six) (1.15.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in e:\\anaconda\\lib\\site-packages (from cryptography->pdfminer.six) (1.14.3)\n",
      "Requirement already satisfied: pycparser in e:\\anaconda\\lib\\site-packages (from cffi!=1.11.3,>=1.8->cryptography->pdfminer.six) (2.20)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfparser import PDFParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import codecs\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "from tika import parser \n",
    "from pandas import DataFrame\n",
    "import PyPDF2\n",
    "\n",
    "# A class is created to extract texts from PDF files\n",
    "\n",
    "class PdfExtracter:\n",
    "    \n",
    "    \n",
    "    def __init__(self, \n",
    "                PATH:str=\"C:\\\\Users\\\\Sangamithra\\\\Desktop\\\\PDFs\",\n",
    "                files:list=[],\n",
    "                lis:list=[]\n",
    "               ):\n",
    "        \n",
    "       \n",
    "        self.PATH = PATH\n",
    "        self.files=files\n",
    "        self.lis=lis\n",
    "\n",
    "        #File extraction method extracts files from the PDF document and prints the document information \n",
    "        \n",
    "    def fileextraction(self):\n",
    "        for file in glob.glob(self.PATH+ \"/*.pdf\"):\n",
    "            if file.endswith('.pdf'):\n",
    "                self.files.append(file)\n",
    "        for i in range(len(self.files)):\n",
    "            print('PDF DOCUMENT NAME: '+ str(self.files[i]))\n",
    "            file_open = open(self.files[i], 'rb')\n",
    "            fileReader = PyPDF2.PdfFileReader(file_open)\n",
    "            print('Number of pages: ' + str(fileReader.numPages))\n",
    "            print('Documentation Info: '+ str(fileReader.documentInfo))\n",
    "            \n",
    "            # Pdf is converted to string and appended to a list\n",
    "            \n",
    "            def convert_pdf_to_string(file_path):\n",
    "                output_string = StringIO()\n",
    "                with open(file_path, 'rb') as in_file:\n",
    "                    parser = PDFParser(in_file)\n",
    "                    doc = PDFDocument(parser)\n",
    "                    rsrcmgr = PDFResourceManager()\n",
    "                    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
    "                    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "                    for page in PDFPage.create_pages(doc):\n",
    "                        interpreter.process_page(page)\n",
    "                return(output_string.getvalue())\n",
    "            text=convert_pdf_to_string(self.files[i])\n",
    "            print(\" -------------------------------------------------------------------------------\")\n",
    "            self.lis.append(text)\n",
    "  #The list is passed  to data cleaning method and removes special characters from the string, Removes white spaces and stores in mod_string\n",
    "    def datacleaning(self):\n",
    "        content=[]\n",
    "        for i in range(len(self.lis)):\n",
    "            content.append(self.lis[i].replace('\\n',''))\n",
    "        mod_string=''.join([str(item) for item in content])\n",
    "        list_of_char = [\"⇑\",\"þ\",\"ð\",\"Þ\",\"ﬃ\",\"ø\",\"•\",\"@\",\":\",\"+\",\"–\",\"â\",\"€\",\"™\",\"#\",\"}\",\"~\",\"=\",\";\",\"(\",\"(cid\",\"cid\",\")\",\"⁄\",\"^\",\"¼\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"0\",\"/\",\"com\",\"Fig.\",\"%\" ,\"[\",\"]\",\"?\",\">\",\"<\",\"±\",\"$\",\"-\",\"©\"]\n",
    "        for character in list_of_char:\n",
    "            mod_string = a=mod_string.replace(character, \"\")\n",
    "        mod_string=re.sub(\"\\s\\s+\",' ',mod_string)\n",
    "        mod_string=mod_string.replace(\"i.e.\", \"That is,\") \n",
    "       # print(mod_string)\n",
    "        final=self.textfile(mod_string)\n",
    "    \n",
    "    #the modified string is then passed to the textfile and converted to csv\n",
    "            \n",
    "    def textfile(self,mod_string):\n",
    "            with codecs.open(\"pdf_extracted.txt\", \"w\", \"utf-8-sig\") as temp:\n",
    "                temp.write(mod_string)\n",
    "            df = pd.read_csv(\"pdf_extracted.txt\",encoding = 'utf-8-sig',header=None,sep='.')\n",
    "            \n",
    "            df=df.T\n",
    "            df.to_csv('pdf_extracted.csv')\n",
    "            csv_row=self.rowreduction()\n",
    "    \n",
    "    # Data cleaning at csv file\n",
    "            \n",
    "    def rowreduction(self):\n",
    "        df = pd.read_csv('pdf_extracted.csv')\n",
    "        new_df = df[df['0'].str.len() <= 20]\n",
    "        cond = df['0'].isin(new_df['0'])\n",
    "        df.drop(df[cond].index, inplace = True)\n",
    "        df.to_csv('pdf_extracted.csv')\n",
    "        csv_drop=self.emptyspace()\n",
    "   \n",
    "    def emptyspace(self):\n",
    "        df = pd.read_csv('pdf_extracted.csv')\n",
    "        df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "      \n",
    "        df.dropna().to_csv('pdf_extracted.csv', index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF DOCUMENT NAME: C:\\Users\\Sangamithra\\Desktop\\PDFs\\07866141-annotated.pdf\n",
      "Number of pages: 5\n",
      "Documentation Info: {'/CreationDate': \"D:20160519161543-07'00'\", '/IEEE#20Article#20ID': '7866141', '/IEEE#20Issue#20ID': '7866072', '/IEEE#20Publication#20ID': '7864767', '/Meeting#20Ending#20Date': '16 June 2016', '/Meeting#20Starting#20Date': '13 June 2016', '/ModDate': \"D:20200617102509-04'00'\", '/Producer': 'iTextSharp 4.0.7 (based on iText 2.0.7); modified using iText® 5.5.6 ©2000-2015 iText Group NV (AGPL-version)', '/Subject': '2016 IEEE First International Conference on Data Science in Cyberspace (DSC);2016; ; ;10.1109/DSC.2016.15', '/Title': 'OPSDS: A Semantic Data Integration and Service System Based on Domain Ontology'}\n",
      " -------------------------------------------------------------------------------\n",
      "PDF DOCUMENT NAME: C:\\Users\\Sangamithra\\Desktop\\PDFs\\1-s2.0-S0020025512002587-main-annotated.pdf\n",
      "Number of pages: 24\n",
      "Documentation Info: {'/Author': 'Mustansar Ali Ghazanfar', '/CreationDate': \"D:20120531102544+05'30'\", '/Creator': 'Elsevier', '/CrossMarkDomains#5B1#5D': 'sciencedirect.com', '/CrossMarkDomains#5B2#5D': 'elsevier.com', '/CrossmarkDomainExclusive': 'true', '/CrossmarkMajorVersionDate': '2010-04-23', '/ElsevierWebPDFSpecifications': '6.2', '/ModDate': \"D:20120531103059+05'30'\", '/Producer': 'Acrobat Distiller 8.1.0 (Windows)', '/Subject': 'Information Sciences, 208 (2012) 81-104. doi:10.1016/j.ins.2012.04.012', '/Title': 'Kernel-Mapping Recommender system algorithms', '/Trapped': '/False', '/doi': '10.1016/j.ins.2012.04.012', '/robots': 'noindex'}\n",
      " -------------------------------------------------------------------------------\n",
      "PDF DOCUMENT NAME: C:\\Users\\Sangamithra\\Desktop\\PDFs\\The-Unreasonable-Effectiveness-of-Data-IEEE-annotated.pdf\n",
      "Number of pages: 6\n",
      "Documentation Info: {'/CreationDate': 'D:20100206035139Z', '/Creator': 'Adobe InDesign CS3 (5.0.4)', '/Producer': 'DynamicPDF for Java v5.0.1', '/rgid': 'PB:224396640_AS:304506271666176@1449611361030'}\n",
      " -------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    pdf_obj=PdfExtracter()\n",
    "    pdf_obj.fileextraction()\n",
    "    pdf_obj.datacleaning()\n",
    "    \n",
    "   \n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
